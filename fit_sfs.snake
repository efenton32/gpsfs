import numpy as np
from twosfs.spectra import Spectra, add_spectra, spectra_from_TreeSequence, load_spectra
import sklearn.gaussian_process as gp
from scipy.stats import norm
import csv
from sim_demography import sim_demography, sim_param_change
from stat_tools import compare_spectra, dict_to_list, batched_prediction, list_to_dict
import json
from itertools import product

data_path = "/n/desai_lab/users/efenton/2sfs/twosfs/agl_data/"

num_sims = 5
samp_size = 63
(a_min, a_max, a_space) = (1.2, 1.81, 0.1)
(mig_min, mig_max, mig_space) = (1e-4, 6e-3, 5e-4)
(time_min, time_max, time_space) = (5.5, 20.6, 1.0)
alpha_vals = np.arange(a_min, a_max, a_space)
t_vals = np.arange(time_min, time_max, time_space)
mig_rates = np.arange(mig_min, mig_max, mig_space)

mig_rates = np.array([1e-4, 2e-4, 5e-4, 1e-3, 2e-3, 4e-3, 8e-3])
t_vals = np.array([1, 2, 4, 8, 10, 20, 40, 80, 100]).astype("float")


generate_anc_rates = product(mig_rates, mig_rates, mig_rates)
generate_new_rates = product(mig_rates, mig_rates, mig_rates)
param_grid = product(alpha_vals, generate_anc_rates, generate_new_rates, t_vals)

# 2 demes
"""
demes = 2
(a_min, a_max, a_space) = (1.01, 1.20, 0.01)
(off_min, off_max, off_space) = (0, 10, 1)
(mig_min, mig_max, mig_space) = (1e-3, 5e-3, 2e-4)


alpha_vals = np.arange(a_min, a_max, a_space)
offset_vals = np.arange(off_min, off_max, off_space)
mig_rates = np.arange(mig_min, mig_max, mig_space)
"""

def previous_batch(wildcards):
    prev_batch = str( int(wildcards.batch) - 1)
    return "sims/{}/results_{}.jsonl".format(wildcards.chr, prev_batch)

ruleorder: initial_samps > generate_samps
rule initial_samps:
    output:
        "sims/{chr}/results_0.jsonl"
    resources:
        mem=1000,
        time=5,
    run:
        alpha_samps = alpha_vals[np.random.randint(0, len(alpha_vals), num_sims)]
        anc_mig_samps = [mig_rates[np.random.randint(0, len(mig_rates), 3)] for i in range(num_sims)]
        new_mig_samps = [mig_rates[np.random.randint(0, len(mig_rates), 3)] for i in range(num_sims)]
        time_samps = t_vals[np.random.randint(0, len(t_vals), num_sims)]

        with open(output[0], "w") as outfile:
            for a, ar, nr, t in zip(alpha_samps, anc_mig_samps, new_mig_samps, time_samps):
                params_dict = {"alpha": float(a),
                               "anc_rates": list(ar),
                               "new_rates": list(nr),
                               "time": t}
                json.dump(params_dict, outfile)
                outfile.write("\n")

rule generate_samps:
    input:
        sims = expand(
            "sims/{chr}/spec_batch_{batch}_rep_{rep}.hdf5",
            rep=range(num_sims),
            allow_missing=True,
        ),
        results_file = previous_batch,
        data_file = "../2sfs/twosfs/agl_data/{chr}/cod_{chr}_initial_spectra.hdf5",
    output:
        "sims/{chr}/results_{batch}.jsonl"
    resources:
        mem=50000,
        time=45,
    run:
        with open(input.results_file) as rf:
            params_dict = [json.loads(line) for line in rf]

        spec_data = load_spectra(str(input.data_file))
        for i, sim in enumerate(input.sims):
            params_dict[i+(int(wildcards.batch)-1)*num_sims]["ks"] = compare_spectra(spec_data, load_spectra(sim))

        ks = np.array([p["ks"] for p in params_dict])
        param_list = np.array([dict_to_list(p) for p in params_dict])[:,:-1]
        n_features = param_list.shape[1]

        k = np.ones(n_features)
        kernel = gp.kernels.RBF(k, (1e-4, 50))
        model = gp.GaussianProcessRegressor(kernel=kernel,
                                            n_restarts_optimizer=10,
                                            alpha=0.01,
                                            normalize_y=True,
                                            copy_X_train=False)

        model.fit(param_list, ks)

        params_predict = []
        for p in param_grid:
            params_predict.append([])
            for x in p:
                try:
                    for y in x:
                        params_predict[-1].append(y)
                except TypeError:
                    params_predict[-1].append(x)

        ks_pred, std = batched_prediction(model, params_predict, int(3e5))
        idx = np.argmin(ks_pred)
        params_min = params_predict[idx]
        ks_min = ks_pred[idx]
        p_imp_rand = norm.cdf(ks_pred - ks_min, std) - (4/(int(wildcards.batch)+1))*np.random.random(len(ks_pred))
        idxs = np.argsort(p_imp_rand)[:num_sims]
        next_pts = [params_predict[i] for i in idxs]
        for pt in next_pts:
            params_dict.append(list_to_dict(pt, ["alpha", "anc_rates", "new_rates", "time"], [1, 3, 3, 1]))

        with open(output[0], "w") as outfile:
            for p in params_dict:
                json.dump(p, outfile)
                outfile.write("\n")

rule run_sims:
    output:
        "sims/{chr}/spec_batch_{batch}_rep_{rep}.hdf5"
    input:
        previous_batch
    resources:
        mem=3000,
        time=20,
    run:
        with open(input[0], "r") as infile:
            for i in range((int(wildcards.batch)-1)*num_sims):
                next(infile)
            for i in range(int(wildcards.rep)):
                next(infile)
            param_dict = json.loads(next(infile))
        sim_param_change(output[0], samples=[36,22,5], num_replicates=int(1e5), **param_dict)

