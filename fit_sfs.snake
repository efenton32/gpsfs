import numpy as np
from twosfs.spectra import Spectra, add_spectra, spectra_from_TreeSequence, load_spectra
import sklearn.gaussian_process as gp
from scipy.stats import norm
import csv
from sim_demography import sim_demography, sim_param_change
from stat_tools import *
import json
from itertools import product

data_path = "/n/desai_lab/users/efenton/2sfs/twosfs/agl_data/"

num_sims = 5
samp_size = 63

(a_min, a_max) = (1.05, 1.85)
(mig_min, mig_max) = (1e-5, 1e-2)
(t_min, t_max) = (0.1, 1000.0)
(c_min, c_max) = (1.0, 1000.0)

def previous_batch(wildcards):
    prev_batch = str( int(wildcards.batch) - 1)
    return "sims/{}/results_{}.jsonl".format(wildcards.chr, prev_batch)

ruleorder: initial_samps > generate_samps
rule initial_samps:
    output:
        "sims/{chr}/results_0.jsonl"
    resources:
        mem=1000,
        time=5,
    run:
        alpha_samps = np.random.random(num_sims) * (a_max - a_min) + a_min
        anc_mig_samps = logify(np.random.random((num_sims, 3)), mig_max, mig_min)
        new_mig_samps = logify(np.random.random((num_sims, 3)), mig_max, mig_min)
        m_time_samps = logify(np.random.random(num_sims), t_max, t_min)
        c_time_samps = logify(np.random.random(num_sims), t_max, t_min)
        contr_samps = logify(np.random.random(num_sims), c_max, c_min)

        with open(output[0], "w") as outfile:
            for a, ar, nr, mt, ct, cf in zip(alpha_samps, anc_mig_samps, new_mig_samps, m_time_samps,
                                             c_time_samps, contr_samps):
                params_dict = {"alpha": float(a),
                               "anc_rates": list(ar),
                               "new_rates": list(nr),
                               "mig_time": mt,
                               "contr_time": ct,
                               "contr_factor": cf}
                json.dump(params_dict, outfile)
                outfile.write("\n")

rule generate_samps:
    input:
        sims = expand(
            "sims/{chr}/spec_batch_{batch}_rep_{rep}.hdf5",
            rep=range(num_sims),
            allow_missing=True,
        ),
        results_file = previous_batch,
        data_file = "../2sfs/twosfs/agl_data/{chr}/cod_{chr}_initial_spectra.hdf5",
    output:
        "sims/{chr}/results_{batch}.jsonl"
    resources:
        mem=10000,
        time=15,
    run:
        with open(input.results_file) as rf:
            params_dict = [json.loads(line) for line in rf]

        spec_data = load_spectra(str(input.data_file))
        for i, sim in enumerate(input.sims):
            params_dict[i+(int(wildcards.batch)-1)*num_sims]["ks"] = compare_spectra(spec_data, load_spectra(sim),
                                                                                     method = "summed_ratio")

        ks = np.array([p["ks"] for p in params_dict])
        param_list = np.array([dict_to_list(p) for p in params_dict])[:,:-1]
        n_features = param_list.shape[1]
        param_list[:, 1:7] = linearize(param_list[:, 1:7], mig_max, mig_min)
        param_list[:, 7:9] = linearize(param_list[:, 7:9], t_max, t_min)
        param_list[:, 9] = linearize(param_list[:, 9], c_max, c_min)

        k = np.ones(n_features)
        kernel = gp.kernels.RBF(k, (1e-5, 1))
        model = gp.GaussianProcessRegressor(kernel=kernel,
                                            n_restarts_optimizer=10,
                                            alpha=0.01,
                                            normalize_y=True,
                                            copy_X_train=False)

        model.fit(param_list, ks)
        next_pts = []
        bounds = np.zeros((n_features, 2)).astype("float")
        bounds[:, 1] = 1.0
        bounds[0, 0] = a_min
        bounds[0, 1] = a_max
        x = find_global_max(expected_val, model, bounds, dx=0.01)
        next_pts.append(x)
        x = find_global_max(prob_of_improvement, model, bounds, dx=0.01, best=min(ks))
        next_pts.append(x)
        x = find_global_max(uncert, model, bounds, dx=0.01)
        next_pts.append(x)

        for pt in next_pts:
            params_dict.append(list_to_dict(
                    pt, ["alpha", "anc_rates", "new_rates", "mig_time", "contr_time", "contr_fact"], [1, 3, 3, 1, 1, 1]
            ))

        with open(output[0], "w") as outfile:
            for p in params_dict:
                json.dump(p, outfile)
                outfile.write("\n")

rule run_sims:
    output:
        "sims/{chr}/spec_batch_{batch}_rep_{rep}.hdf5"
    input:
        previous_batch
    resources:
        mem=3000,
        time=20,
    run:
        with open(input[0], "r") as infile:
            for i in range((int(wildcards.batch)-1)*num_sims):
                next(infile)
            for i in range(int(wildcards.rep)):
                next(infile)
            param_dict = json.loads(next(infile))
        sim_param_change(output[0], samples=[28,22,13], num_replicates=int(1e3), **param_dict)

